{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5759f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ANNModel as ann\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14e54ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset(dataset, path):\n",
    "        labels = os.listdir(os.path.join(path, dataset))\n",
    "        X = []\n",
    "        y = []\n",
    "        for label in labels:\n",
    "            for file in os.listdir(os.path.join(path, dataset, label)):\n",
    "                image = cv2.imread(os.path.join(path, dataset, label, file),cv2.IMREAD_UNCHANGED)\n",
    "                X.append(image)\n",
    "                y.append(label)\n",
    "        return np.array(X), np.array(y).astype('uint8')\n",
    "    \n",
    "def create_data_mnist(path):\n",
    "    X, y = load_mnist_dataset('train', path)\n",
    "    X_test, y_test = load_mnist_dataset('test', path)\n",
    "    return X, y, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1667c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 0, acc: 0.086, loss: 2.303 (data_loss: 2.303, reg_loss: 0.000), lr: 0.001\n",
      "step: 100, acc: 0.719, loss: 0.807 (data_loss: 0.807, reg_loss: 0.000), lr: 0.0009090909090909091\n",
      "step: 200, acc: 0.703, loss: 0.688 (data_loss: 0.688, reg_loss: 0.000), lr: 0.0008333333333333334\n",
      "step: 300, acc: 0.828, loss: 0.463 (data_loss: 0.463, reg_loss: 0.000), lr: 0.0007692307692307692\n",
      "step: 400, acc: 0.789, loss: 0.512 (data_loss: 0.512, reg_loss: 0.000), lr: 0.0007142857142857144\n",
      "step: 468, acc: 0.823, loss: 0.461 (data_loss: 0.461, reg_loss: 0.000), lr: 0.0006811989100817438\n",
      "training, acc: 0.755, loss: 0.655 (data_loss: 0.655, reg_loss: 0.000), lr: 0.0006811989100817438\n",
      "validation, acc: 0.824, loss: 0.489\n",
      "epoch: 2\n",
      "step: 0, acc: 0.812, loss: 0.543 (data_loss: 0.543, reg_loss: 0.000), lr: 0.0006807351940095302\n",
      "step: 100, acc: 0.844, loss: 0.498 (data_loss: 0.498, reg_loss: 0.000), lr: 0.0006373486297004462\n",
      "step: 200, acc: 0.773, loss: 0.500 (data_loss: 0.500, reg_loss: 0.000), lr: 0.0005991611743559018\n",
      "step: 300, acc: 0.875, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.0005652911249293386\n",
      "step: 400, acc: 0.852, loss: 0.439 (data_loss: 0.439, reg_loss: 0.000), lr: 0.0005350454788657035\n",
      "step: 468, acc: 0.854, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.0005162622612287042\n",
      "training, acc: 0.844, loss: 0.427 (data_loss: 0.427, reg_loss: 0.000), lr: 0.0005162622612287042\n",
      "validation, acc: 0.843, loss: 0.440\n",
      "epoch: 3\n",
      "step: 0, acc: 0.781, loss: 0.506 (data_loss: 0.506, reg_loss: 0.000), lr: 0.0005159958720330237\n",
      "step: 100, acc: 0.867, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000), lr: 0.0004906771344455348\n",
      "step: 200, acc: 0.805, loss: 0.425 (data_loss: 0.425, reg_loss: 0.000), lr: 0.0004677268475210477\n",
      "step: 300, acc: 0.859, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000), lr: 0.00044682752457551384\n",
      "step: 400, acc: 0.859, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.000427715996578272\n",
      "step: 468, acc: 0.854, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000), lr: 0.00041562759767248546\n",
      "training, acc: 0.861, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.00041562759767248546\n",
      "validation, acc: 0.850, loss: 0.415\n",
      "epoch: 4\n",
      "step: 0, acc: 0.820, loss: 0.460 (data_loss: 0.460, reg_loss: 0.000), lr: 0.0004154549231408392\n",
      "step: 100, acc: 0.883, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000), lr: 0.00039888312724371757\n",
      "step: 200, acc: 0.844, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000), lr: 0.0003835826620636747\n",
      "step: 300, acc: 0.867, loss: 0.352 (data_loss: 0.352, reg_loss: 0.000), lr: 0.00036941263391207984\n",
      "step: 400, acc: 0.852, loss: 0.401 (data_loss: 0.401, reg_loss: 0.000), lr: 0.0003562522265764161\n",
      "step: 468, acc: 0.865, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.00034782608695652176\n",
      "training, acc: 0.870, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.00034782608695652176\n",
      "validation, acc: 0.855, loss: 0.401\n",
      "epoch: 5\n",
      "step: 0, acc: 0.812, loss: 0.438 (data_loss: 0.438, reg_loss: 0.000), lr: 0.0003477051460361613\n",
      "step: 100, acc: 0.891, loss: 0.361 (data_loss: 0.361, reg_loss: 0.000), lr: 0.0003360215053763441\n",
      "step: 200, acc: 0.859, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000), lr: 0.00032509752925877764\n",
      "step: 300, acc: 0.867, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000), lr: 0.00031486146095717883\n",
      "step: 400, acc: 0.875, loss: 0.388 (data_loss: 0.388, reg_loss: 0.000), lr: 0.00030525030525030525\n",
      "step: 468, acc: 0.865, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000), lr: 0.000299043062200957\n",
      "training, acc: 0.876, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000), lr: 0.000299043062200957\n",
      "validation, acc: 0.860, loss: 0.391\n",
      "epoch: 6\n",
      "step: 0, acc: 0.812, loss: 0.423 (data_loss: 0.423, reg_loss: 0.000), lr: 0.0002989536621823617\n",
      "step: 100, acc: 0.914, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000), lr: 0.0002902757619738752\n",
      "step: 200, acc: 0.875, loss: 0.344 (data_loss: 0.344, reg_loss: 0.000), lr: 0.0002820874471086037\n",
      "step: 300, acc: 0.883, loss: 0.324 (data_loss: 0.324, reg_loss: 0.000), lr: 0.00027434842249657066\n",
      "step: 400, acc: 0.883, loss: 0.375 (data_loss: 0.375, reg_loss: 0.000), lr: 0.000267022696929239\n",
      "step: 468, acc: 0.875, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000), lr: 0.00026226068712300026\n",
      "training, acc: 0.881, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000), lr: 0.00026226068712300026\n",
      "validation, acc: 0.862, loss: 0.382\n",
      "epoch: 7\n",
      "step: 0, acc: 0.828, loss: 0.407 (data_loss: 0.407, reg_loss: 0.000), lr: 0.00026219192448872575\n",
      "step: 100, acc: 0.914, loss: 0.323 (data_loss: 0.323, reg_loss: 0.000), lr: 0.00025549310168625444\n",
      "step: 200, acc: 0.883, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000), lr: 0.00024912805181863477\n",
      "step: 300, acc: 0.891, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.0002430724355858046\n",
      "step: 400, acc: 0.883, loss: 0.365 (data_loss: 0.365, reg_loss: 0.000), lr: 0.00023730422401518745\n",
      "step: 468, acc: 0.875, loss: 0.338 (data_loss: 0.338, reg_loss: 0.000), lr: 0.00023353573096683794\n",
      "training, acc: 0.884, loss: 0.318 (data_loss: 0.318, reg_loss: 0.000), lr: 0.00023353573096683794\n",
      "validation, acc: 0.865, loss: 0.374\n",
      "epoch: 8\n",
      "step: 0, acc: 0.852, loss: 0.396 (data_loss: 0.396, reg_loss: 0.000), lr: 0.0002334812047630166\n",
      "step: 100, acc: 0.906, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.00022815423226100844\n",
      "step: 200, acc: 0.883, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000), lr: 0.0002230649118893598\n",
      "step: 300, acc: 0.898, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.0002181976871045167\n",
      "step: 400, acc: 0.898, loss: 0.356 (data_loss: 0.356, reg_loss: 0.000), lr: 0.0002135383301302584\n",
      "step: 468, acc: 0.875, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000), lr: 0.0002104820037886761\n",
      "training, acc: 0.888, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000), lr: 0.0002104820037886761\n",
      "validation, acc: 0.867, loss: 0.369\n",
      "epoch: 9\n",
      "step: 0, acc: 0.859, loss: 0.384 (data_loss: 0.384, reg_loss: 0.000), lr: 0.0002104377104377104\n",
      "step: 100, acc: 0.906, loss: 0.303 (data_loss: 0.303, reg_loss: 0.000), lr: 0.00020610057708161583\n",
      "step: 200, acc: 0.891, loss: 0.311 (data_loss: 0.311, reg_loss: 0.000), lr: 0.00020193861066235866\n",
      "step: 300, acc: 0.898, loss: 0.310 (data_loss: 0.310, reg_loss: 0.000), lr: 0.0001979414093428345\n",
      "step: 400, acc: 0.898, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000), lr: 0.00019409937888198756\n",
      "step: 468, acc: 0.875, loss: 0.313 (data_loss: 0.313, reg_loss: 0.000), lr: 0.00019157088122605365\n",
      "training, acc: 0.890, loss: 0.301 (data_loss: 0.301, reg_loss: 0.000), lr: 0.00019157088122605365\n",
      "validation, acc: 0.869, loss: 0.365\n",
      "epoch: 10\n",
      "step: 0, acc: 0.859, loss: 0.373 (data_loss: 0.373, reg_loss: 0.000), lr: 0.0001915341888527102\n",
      "step: 100, acc: 0.906, loss: 0.295 (data_loss: 0.295, reg_loss: 0.000), lr: 0.00018793459875963167\n",
      "step: 200, acc: 0.898, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000), lr: 0.00018446781036709093\n",
      "step: 300, acc: 0.898, loss: 0.305 (data_loss: 0.305, reg_loss: 0.000), lr: 0.00018112660749864155\n",
      "step: 400, acc: 0.898, loss: 0.341 (data_loss: 0.341, reg_loss: 0.000), lr: 0.0001779042874933286\n",
      "step: 468, acc: 0.875, loss: 0.301 (data_loss: 0.301, reg_loss: 0.000), lr: 0.00017577781683951485\n",
      "training, acc: 0.893, loss: 0.294 (data_loss: 0.294, reg_loss: 0.000), lr: 0.00017577781683951485\n",
      "validation, acc: 0.870, loss: 0.361\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test, y_test = create_data_mnist('fashion_mnist_images')\n",
    "\n",
    "keys = np.array(range(X.shape[0]))\n",
    "np.random.shuffle(keys)\n",
    "X = X[keys]\n",
    "y = y[keys]\n",
    "\n",
    "X = (X.reshape(X.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
    "X_test = (X_test.reshape(X_test.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "model = ann.Model()\n",
    "\n",
    "model.add(ann.Layer_Dense(X.shape[1], 128))\n",
    "model.add(ann.Activation_ReLU())\n",
    "model.add(ann.Layer_Dense(128, 128))\n",
    "model.add(ann.Activation_ReLU())\n",
    "model.add(ann.Layer_Dense(128, 10))\n",
    "model.add(ann.Activation_Softmax())\n",
    "\n",
    "model.set(\n",
    "    loss=ann.Loss_CategoricalCrossentropy(),\n",
    "    optimizer=ann.Optimizer_Adam(decay=1e-3),\n",
    "    accuracy=ann.Accuracy_Categorical()\n",
    ")\n",
    "\n",
    "model.finalize()\n",
    "\n",
    "model.train(X, y, validation_data=(X_test, y_test),epochs=10, batch_size=128, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f804490b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.870, loss: 0.361\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77b1b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fashion_mnist.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
